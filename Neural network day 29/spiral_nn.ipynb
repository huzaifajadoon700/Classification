{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a65a79",
   "metadata": {},
   "source": [
    "# Neural Network for Spiral Data Classification\n",
    "\n",
    "Implementation of a neural network to classify spiral data points into three classes (red, green, blue) using TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd86095",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baaba683",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df8ea5",
   "metadata": {},
   "source": [
    "## 2. Generate Spiral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8815c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spiral data\n",
    "N = 333  # number of points per class\n",
    "K = 3    # number of classes\n",
    "X = np.zeros((N*K, 2))  # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8')  # class labels\n",
    "\n",
    "for j in range(K):\n",
    "    ix = range(N*j, N*(j+1))\n",
    "    r = np.linspace(0.0, 1, N)  # radius\n",
    "    t = np.linspace(j*4, (j+1)*4, N) + np.random.randn(N)*0.2  # theta\n",
    "    X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "    y[ix] = j\n",
    "\n",
    "# Plot the generated data\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)\n",
    "plt.title(\"Generated Spiral Data\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165b328",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445035b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_onehot = np.eye(K)[y_train]\n",
    "y_test_onehot = np.eye(K)[y_test]\n",
    "\n",
    "# Visualize scaled training data\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, cmap=plt.cm.RdYlBu)\n",
    "plt.title(\"Scaled Training Data\")\n",
    "plt.xlabel(\"X1 (scaled)\")\n",
    "plt.ylabel(\"X2 (scaled)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567a534",
   "metadata": {},
   "source": [
    "## 4. Define Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a6bef",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_onehot,\n",
    "                   epochs=50,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(X_test_scaled, y_test_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdece2",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a61ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Plot true vs predicted classes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.RdYlBu)\n",
    "ax1.set_title('True Classes')\n",
    "ax1.set_xlabel('X1')\n",
    "ax1.set_ylabel('X2')\n",
    "\n",
    "ax2.scatter(X_test[:, 0], X_test[:, 1], c=y_pred_classes, cmap=plt.cm.RdYlBu)\n",
    "ax2.set_title('Predicted Classes')\n",
    "ax2.set_xlabel('X1')\n",
    "ax2.set_ylabel('X2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ca393",
   "metadata": {},
   "source": [
    "## 7. Test with New Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c903fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a new point\n",
    "new_point = np.array([[0.1, -5]])\n",
    "new_point_scaled = scaler.transform(new_point)\n",
    "prediction = model.predict(new_point_scaled)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, alpha=0.5)\n",
    "plt.scatter(new_point[0, 0], new_point[0, 1], c='yellow', s=200, label='New Point')\n",
    "plt.title(f'New Point Classification\\nPredicted Class: {predicted_class}')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042edb0",
   "metadata": {},
   "source": [
    "## 8. Compare Different Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14002976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train model with different optimizers\n",
    "def train_with_optimizer(optimizer_name):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(2,)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer = 'sgd'\n",
    "    elif optimizer_name == 'sgd_momentum':\n",
    "        optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "    else:\n",
    "        optimizer = 'adam'\n",
    "        \n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train_scaled, y_train_onehot,\n",
    "                       epochs=50,\n",
    "                       batch_size=32,\n",
    "                       validation_data=(X_test_scaled, y_test_onehot),\n",
    "                       verbose=0)\n",
    "    return history\n",
    "\n",
    "# Train with different optimizers\n",
    "optimizers = ['adam', 'sgd', 'sgd_momentum']\n",
    "histories = {opt: train_with_optimizer(opt) for opt in optimizers}\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "for opt in optimizers:\n",
    "    plt.plot(histories[opt].history['accuracy'], label=opt)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "for opt in optimizers:\n",
    "    plt.plot(histories[opt].history['val_accuracy'], label=opt)\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
