{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d429cd62",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification using CNN\n",
    "\n",
    "This notebook implements a Convolutional Neural Network (CNN) to classify brain MRI scans into two categories:\n",
    "1. Brain Tumor Present (Yes)\n",
    "2. Brain Tumor Absent (No)\n",
    "\n",
    "The model will be trained on a dataset of MRI scans and will learn to identify the presence of tumors with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2169bf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll import the necessary libraries for building our CNN model:\n",
    "- Keras/TensorFlow for building and training the CNN\n",
    "- scikit-learn for data splitting and preprocessing\n",
    "- numpy for numerical operations\n",
    "- matplotlib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ef3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Import scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# For reading image files\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da187fd",
   "metadata": {},
   "source": [
    "## 2. Data Import and Preprocessing\n",
    "\n",
    "In this section, we will:\n",
    "1. Load MRI images from the dataset\n",
    "2. Resize all images to 128x128x3 dimension\n",
    "3. Convert labels to one-hot encoded format\n",
    "4. Combine data from both classes (tumor present/absent)\n",
    "\n",
    "The dataset contains two folders:\n",
    "- 'yes': Contains MRI scans with brain tumors\n",
    "- 'no': Contains MRI scans without brain tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104bac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m result = np.array(result)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# One-hot encode the labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m encoder = \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m result = encoder.fit_transform(result.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset shape:\u001b[39m\u001b[33m\"\u001b[39m, data.shape)\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# This cell has been updated with improved image loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fddf2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n",
      "Found 310 images in tumor class\n",
      "Found 196 images in no-tumor class\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m result = np.array(result)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# One-hot encode the labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m encoder = \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m result = encoder.fit_transform(result.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDataset Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store data\n",
    "data = []  # For storing image data\n",
    "result = []  # For storing labels\n",
    "paths = []  # For storing image paths\n",
    "\n",
    "# Image dimensions\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        # Load and resize image\n",
    "        img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        # Convert to array and normalize\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to get all image files with various extensions\n",
    "def get_image_files(directory):\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG']\n",
    "    image_files = []\n",
    "    for ext in extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(directory, ext)))\n",
    "    return image_files\n",
    "\n",
    "print(\"Loading and preprocessing images...\")\n",
    "\n",
    "# Load 'yes' (tumor) images\n",
    "yes_path = 'brain_tumor_dataset/yes'\n",
    "yes_files = get_image_files(yes_path)\n",
    "print(f\"Found {len(yes_files)} images in tumor class\")\n",
    "\n",
    "for img_path in yes_files:\n",
    "    img = load_and_preprocess_image(img_path)\n",
    "    if img is not None:\n",
    "        data.append(img)\n",
    "        result.append(1)  # 1 for tumor present\n",
    "        paths.append(img_path)\n",
    "\n",
    "# Load 'no' (no tumor) images\n",
    "no_path = 'brain_tumor_dataset/no'\n",
    "no_files = get_image_files(no_path)\n",
    "print(f\"Found {len(no_files)} images in no-tumor class\")\n",
    "\n",
    "for img_path in no_files:\n",
    "    img = load_and_preprocess_image(img_path)\n",
    "    if img is not None:\n",
    "        data.append(img)\n",
    "        result.append(0)  # 0 for tumor absent\n",
    "        paths.append(img_path)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "result = encoder.fit_transform(result.reshape(-1, 1))\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(\"Total images loaded:\", len(data))\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"Labels shape:\", result.shape)\n",
    "print(f\"Number of tumor images: {sum(result[:,1])}\")\n",
    "print(f\"Number of no-tumor images: {sum(result[:,0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d7041",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split\n",
    "\n",
    "We'll split our dataset into:\n",
    "- Training set (80% of data)\n",
    "- Testing set (20% of data)\n",
    "\n",
    "This split ensures we can evaluate our model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, \n",
    "    result,\n",
    "    test_size=0.2,    # 20% for testing\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "\n",
    "# Print the shapes of training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332abfd3",
   "metadata": {},
   "source": [
    "## 4. CNN Model Architecture\n",
    "\n",
    "We'll build a CNN with the following components:\n",
    "1. Convolutional layers with ReLU activation\n",
    "2. MaxPooling layers for downsampling\n",
    "3. Batch Normalization for stabilizing training\n",
    "4. Dropout layers to prevent overfitting\n",
    "5. Dense layers for final classification\n",
    "\n",
    "The architecture follows this pattern:\n",
    "- Conv2D -> ReLU -> BatchNorm -> MaxPool -> Dropout\n",
    "- Conv2D -> ReLU -> BatchNorm -> MaxPool -> Dropout\n",
    "- Flatten\n",
    "- Dense -> Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e75e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First set of Conv -> ReLU -> BatchNorm -> MaxPool -> Dropout\n",
    "model.add(Conv2D(32, (2, 2), input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second set of Conv -> ReLU -> BatchNorm -> MaxPool -> Dropout\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers with dropout\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))  # 2 classes: tumor present/absent\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adamax',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be361f1",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We'll train the model for 30 epochs with the following parameters:\n",
    "- Batch size: 32\n",
    "- Validation split: 20% of training data\n",
    "- Monitor both training and validation loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edaa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the training and validation metrics\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal Training Accuracy:\", train_accuracy[-1])\n",
    "print(\"Final Validation Accuracy:\", val_accuracy[-1])\n",
    "print(\"Final Training Loss:\", train_loss[-1])\n",
    "print(\"Final Validation Loss:\", val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3aaf1",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Visualization\n",
    "\n",
    "Let's visualize the training process by plotting:\n",
    "1. Training vs Validation Loss\n",
    "2. Training vs Validation Accuracy\n",
    "\n",
    "This will help us understand if the model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e179e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e452e",
   "metadata": {},
   "source": [
    "## 7. Testing Model Predictions\n",
    "\n",
    "Let's test our model on some sample images from the test set and visualize:\n",
    "1. The input MRI scan\n",
    "2. The true label\n",
    "3. The model's prediction with confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predict_tumor(image, true_label):\n",
    "    # Make prediction\n",
    "    pred = model.predict(image.reshape(1, IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "    pred_class = np.argmax(pred)\n",
    "    pred_prob = pred[0][pred_class]\n",
    "    \n",
    "    # Convert true label from one-hot encoding\n",
    "    true_class = np.argmax(true_label)\n",
    "    \n",
    "    # Create labels for display\n",
    "    class_labels = ['No Tumor', 'Tumor Present']\n",
    "    \n",
    "    # Plot the image and predictions\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'True: {class_labels[true_class]}\\nPrediction: {class_labels[pred_class]} ({pred_prob:.2%})')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Test on a few random images from test set\n",
    "for i in range(3):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    predict_tumor(X_test[idx], y_test[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
